---
title: "Strategies for working with new data"
author: 'Sharla Gelfand'
date: '2019-03-05'
slug: new-data-strategies
---



<p>(This post is a basically a blog-replicate of a talk I gave at the R-Ladies Toronto + GTA R User Group kickoff, called <a href="https://sharla.party/talks/rladies-rug-kickoff.html#1">â€œOpinionated Strategies for Uncharted Territoriesâ€</a> â€“ if you saw that, this is old news ğŸ’…)</p>
<p>A few weeks ago the TTC launched a new campaign around <em>not</em> going onto the tracks to retrieve dropped items â€“ â€œitâ€™s not worth your life.â€ Pretty reasonable, right?</p>
<p>This came along with some press saying that unauthorized people at the track level caused 26 hours of delays on the TTC last year (this includes people going onto tracks to get their belongs, people sneaking into tunnels, etc. Probably not when people drive into tunnels).</p>
<p>I was curious to see how this varied from line to line, what are the most common stations where people go onto the tracks (!), and what the other causes of delay were.</p>
<p>Luckily, <a href="https://www.toronto.ca/city-government/data-research-maps/open-data/open-data-catalogue/transportation/#917dd033-1fe5-4ba8-04ca-f683eec89761">Toronto Open Data</a> releases TTC delays and has all of the 2018 delays. My goal is to answer a few of these questions about TTC delays, and to showcase some strategies for working with a new data set.</p>
<p>Letâ€™s look at the data.</p>
<p>(A small disclaimer, and my apologies to the TTC and Toronto Open Data â€“ I messed with this data. Just a bit. Some of the errors are yours, some are mine. You can see the messing around I did <a href="">here</a>).</p>
<pre class="r"><code>delays</code></pre>
<pre><code>## # A tibble: 20,735 x 8
##    date       time  station   code  description       min_delay bound line 
##    &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;
##  1 2018-04-01 00:27 ST GEORGâ€¦ MUSAN Unsanitary Vehicâ€¦         8 W     BD   
##  2 2018-04-01 07:56 FINCH STâ€¦ TUSC  Operator Overspeâ€¦         0 S     YU   
##  3 2018-04-01 08:00 YONGE UNâ€¦ MUO   Miscellaneous Otâ€¦         0 &lt;NA&gt;  YU   
##  4 2018-04-01 09:50 KIPLING â€¦ TUSC  Operator Overspeâ€¦         0 W     BD   
##  5 2018-04-01 10:18 VICTORIAâ€¦ MUSC  Miscellaneous Spâ€¦         0 W     BD   
##  6 2018-04-01 10:22 KENNEDY â€¦ EUNT  Equipment - No Tâ€¦         3 W     BD   
##  7 2018-04-01 10:30 WILSON Sâ€¦ PUMEL Escalator/Elevatâ€¦         0 &lt;NA&gt;  YU   
##  8 2018-04-01 11:20 WILSON Sâ€¦ TUSC  Operator Overspeâ€¦         0 S     YU   
##  9 2018-04-01 11:32 FINCH WEâ€¦ MUIRS Injured or ill Câ€¦         0 &lt;NA&gt;  YU   
## 10 2018-04-01 12:00 JANE STAâ€¦ TUSC  Operator Overspeâ€¦         0 W     BD   
## # â€¦ with 20,725 more rows</code></pre>
<p>Looks good!</p>
<p>Now, I want to look at the top 5 causes for delay along each line (YU, BD, SHP, and SRT), and see the total delays they caused in 2018. <code>min_delay</code> shows the delay time, in minutes, so we can use that.</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)

delays %&gt;%
  group_by(line, code) %&gt;%
  summarise(delays = sum(min_delay)) %&gt;%
  arrange(-delays) %&gt;%
  slice(1:5) %&gt;%
  ggplot(aes(x = code,
             y = delays)) +
  geom_col() + 
  facet_wrap(vars(line), 
             scales = &quot;free_y&quot;,
             nrow = 4) +
  coord_flip()</code></pre>
<pre><code>## Warning: Removed 3 rows containing missing values (position_stack).</code></pre>
<p><img src="/posts/2019/2019-03-05-new-data-strategies_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>So, this is definitely not what I expected, nor what the datasetâ€™s documentation says to expect (that the line should be one of YU, BD, SHP, and SRT).</p>
<p>There are a bunch of â€œotherâ€ â€œlinesâ€ with varying amounts of data and definitely â€œline-nessâ€ in general â€“ 16 MCCOWAN is not a subway line and â€œYU/BDâ€ appears in various spellings (probably for delays at Yonge, St.Â George, and Spadina stations?).</p>
<p>So letâ€™s just focus on the actual lines.</p>
<pre class="r"><code>delays %&gt;%
  filter(line %in% c(&quot;BD&quot;, &quot;YU&quot;, 
                     &quot;SHP&quot;, &quot;SRT&quot;)) %&gt;% 
  group_by(line, description) %&gt;%
  summarise(delays = sum(min_delay)) %&gt;%
  arrange(-delays) %&gt;%
  slice(1:5) %&gt;%
  ggplot(aes(x = description,
             y = delays)) +
  geom_col() + 
  facet_wrap(vars(line), 
             scales = &quot;free_x&quot;,
             nrow = 1) +
  coord_flip() </code></pre>
<p><img src="/posts/2019/2019-03-05-new-data-strategies_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>This is now, apparently, the top 5 causes for delay on each line. We see some interesting things here that are more popular than Iâ€™d have thought â€“ â€œBomb Threatâ€, â€œSuspicious Packageâ€, â€œForce Majeureâ€ (i.e., a force of nature, absolving the TTC of responsibility) rank pretty high.</p>
<p>But no where is â€œUnauthorized at Track Levelâ€! So letâ€™s focus on that.</p>
<pre class="r"><code>delays %&gt;%
  filter(description == &quot;Unauthorized at Track Level&quot;) %&gt;%
  group_by(line) %&gt;%
  summarise(delays = sum(min_delay))</code></pre>
<pre><code>## # A tibble: 4 x 2
##   line  delays
##   &lt;chr&gt;  &lt;dbl&gt;
## 1 BD        NA
## 2 SHP        7
## 3 SRT        0
## 4 YU        NA</code></pre>
<p>You might be familiar with whatâ€™s happening here â€“ there are <code>NA</code> values in the data, which causes the <code>sum</code> to be <code>NA</code>, but it has an easy fix!</p>
<pre class="r"><code>delays %&gt;%
  filter(description == &quot;Unauthorized at Track Level&quot;) %&gt;%
  group_by(line) %&gt;%
  summarise(delays = sum(min_delay, na.rm = TRUE))</code></pre>
<pre><code>## # A tibble: 4 x 2
##   line  delays
##   &lt;chr&gt;  &lt;dbl&gt;
## 1 BD       644
## 2 SHP        7
## 3 SRT        0
## 4 YU       860</code></pre>
<p>This also affects our first couple of plots, which showed the top 5 delays for each line â€“ any delay code that has an <code>NA</code> value therefore has a total delay of <code>NA</code>, and wouldnâ€™t have made the cut when we ranked the lines by delay; so even if it <em>was</em> the top delay, it would be missing.</p>
<p>So, I want to talk about some strategies for avoiding this. Sure, itâ€™s not that bad to have to go back and add in the <code>na.rm = TRUE</code>, or to filter your data and ensure consistent coding, but it would be really nice to <em>know</em> that you have to do this up front. Itâ€™d also be nice to know <em>what</em> you have to do right away, and not rely on â€œdoing something with that variableâ€ to notice the mistake.</p>
<div id="visual-summaries" class="section level1">
<h1>Visual Summaries</h1>
<p>The first strategy I want to talk about is simple, but really powerful, and thatâ€™s <em>getting a visual summary of your data</em>. I want to be able to learn as much about my data, its structure and its attributes, as fast as possible.</p>
<div id="visdat-package" class="section level2">
<h2><code>visdat</code> package</h2>
<p>A great way to get a visual overview of your data structure is through the <a href="https://github.com/ropensci/visdat"><code>visdat</code> package</a>, created by <a href="https://www.njtierney.com/">Nick Tierney</a>. This package allows you to â€œget a look at the dataâ€ by visualizing the data frame and any missingness.</p>
<pre class="r"><code>library(visdat)

vis_dat(delays)</code></pre>
<p><img src="/posts/2019/2019-03-05-new-data-strategies_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>By doing this, we learn a bit about our data that <em>wasnâ€™t</em> apparent just from looking at the first 10 lines. It shows us the variable types, and any missingness.</p>
<ul>
<li>Sometimes the <code>code</code> doesnâ€™t have a corresponding <code>description</code></li>
<li>Sometimes <code>bound</code> and <code>line</code> are missing</li>
<li>Sometimes <code>min_delay</code> is missing!</li>
</ul>
<p>And if we want to get a better handle on what percent of our data is missing, we can use <code>vis_miss()</code>.</p>
<pre class="r"><code>vis_miss(delays)</code></pre>
<p><img src="/posts/2019/2019-03-05-new-data-strategies_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>This actually reports <em>what percent</em> of data is missing, both for each variable and overall. For example, the codeâ€™s <code>description</code> is missing about 2% of the time, the actual delay time (<code>min_delay</code>) is missing 5% of the time, and <code>bound</code> is missing almost 25% of the time!</p>
<p>Just doing this can spark some questions that we might not have had before:</p>
<ul>
<li>When is <code>description</code> missing? Are there specific <code>code</code>s that just donâ€™t have a corresponding description? Was the <code>code</code> just entered incorrectly, and should be recoded to match an existing code?</li>
<li>Why is the <code>min_delay</code> missing?</li>
<li>What does it <em>mean</em> for <code>bound</code> to be missing? Is it that the delay was in both directions? Do certain types of delays not have a <code>bound</code>?</li>
</ul>
<p>And by following up on these questions, either by exploring the data or <em>asking people for the answers</em>, we can learn a ton about TTC delays and about this data set.</p>
<p>Doing this also gives us the knowledge that <em>sometimes <code>min_delay</code> is missing</em>, and we will need to handle that properly in any calculations with it!</p>
</div>
<div id="variable-summaries" class="section level2">
<h2>Variable summaries</h2>
<p>The next thing Iâ€™d probably want to do is understand the different attributes of each variable, the values it can take on, etc.</p>
<p>One of the most classic ways to do this is by using the <code>summary()</code> function, e.g.</p>
<pre class="r"><code>summary(delays[[&quot;min_delay&quot;]])</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   0.000   0.000   2.345   3.000 515.000    1036</code></pre>
<p>which tells us a bit about the distribution of the data, and how many <code>NA</code>s there are,</p>
<p>or,</p>
<pre class="r"><code>summary(delays[[&quot;line&quot;]])</code></pre>
<pre><code>##    Length     Class      Mode 
##     20735 character character</code></pre>
<p>which tells you absolutely nothing.</p>
<p><code>summary()</code>, in all its generality-glory, works on a ton of different classes of objects. Unfortunately it is in varying utility â€“ for a numeric vector, you get a lot of information. For a character vector, you get nothing useful.</p>
<p>Itâ€™s also annoying to go variable-by-variable. Sure, you can use <code>summary()</code> on a whole data frame,</p>
<pre class="r"><code>summary(delays)</code></pre>
<pre><code>##       date                time             station         
##  Min.   :2018-01-01   Length:20735       Length:20735      
##  1st Qu.:2018-04-05   Class :character   Class :character  
##  Median :2018-07-05   Mode  :character   Mode  :character  
##  Mean   :2018-07-01                                        
##  3rd Qu.:2018-09-27                                        
##  Max.   :2018-12-31                                        
##                                                            
##      code           description          min_delay      
##  Length:20735       Length:20735       Min.   :  0.000  
##  Class :character   Class :character   1st Qu.:  0.000  
##  Mode  :character   Mode  :character   Median :  0.000  
##                                        Mean   :  2.345  
##                                        3rd Qu.:  3.000  
##                                        Max.   :515.000  
##                                        NA&#39;s   :1036     
##     bound               line          
##  Length:20735       Length:20735      
##  Class :character   Class :character  
##  Mode  :character   Mode  :character  
##                                       
##                                       
##                                       
## </code></pre>
<p>but this isnâ€™t a great way to visualize the information, with varying degrees of usefulness and all jumbled up.</p>
</div>
<div id="skimr-package" class="section level2">
<h2><code>skimr</code> package</h2>
<p>The <a href="https://github.com/ropensci/skimr"><code>skimr</code> package</a>, maintained by <a href="https://elinwaring.org/">Elin Waring</a> and <a href="http://michaelquinn32.github.io/">Michael Quinn</a>, is a great solution to this. Itâ€™s designed to show summary statistics that you can quickly <em>skim</em> to understand your data.</p>
<p><code>skimr</code> also conforms to something called the â€œPrinciple of Least Surpriseâ€, which I thought was really interesting. Itâ€™s a concept from UI and software design that basically says the behaviour of something shouldnâ€™t surprise a user, and that the design (of the UI or software) should match the userâ€™s experience, expectations, and mental models.</p>
<p>I (and obviously the creators of <code>skimr</code>) think this applies to data so nicely. The <strong>data</strong> should match your experience, expectations, and mental models. And if it doesnâ€™t, you should find out quickly!</p>
<p>The <code>skim()</code> function shows summary statistics for each variable, separated by variable class (e.g.Â all character variables together, all integers together, etc).</p>
<pre class="r"><code>library(skimr)

delays %&gt;%
  skim()</code></pre>
<pre><code>## Skim summary statistics
##  n obs: 20735 
##  n variables: 8 
## 
## â”€â”€ Variable type:character â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
##     variable missing complete     n min max empty n_unique
##        bound    4698    16037 20735   1   1     0        6
##         code       0    20735 20735   3   5     0      184
##  description     462    20273 20735   4  58     0      132
##         line     101    20634 20735   2  11     0       13
##      station       0    20735 20735   8  22     0      201
##         time       0    20735 20735   5   5     0     1388
## 
## â”€â”€ Variable type:Date â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
##  variable missing complete     n        min        max     median n_unique
##      date       0    20735 20735 2018-01-01 2018-12-31 2018-07-05      365
## 
## â”€â”€ Variable type:numeric â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
##   variable missing complete     n mean   sd p0 p25 p50 p75 p100     hist
##  min_delay    1036    19699 20735 2.34 8.62  0   0   0   3  515 â–‡â–â–â–â–â–â–â–</code></pre>
<p>For all variables, it tells you how many are <code>missing</code>, how many are <code>complete</code> (i.e., not missing), and the total count, <code>n</code>.</p>
<p>For character variables, it shows the <code>min</code> and <code>max</code> length of non-empty strings in that variable, the number of empty strings (i.e., <code>&quot;&quot;</code> â€“ this is great if you might have some things that should be <code>NA</code> masquerading as empty strings!), and the number of unique strings.</p>
<p>For numeric variables, it shows the mean, sd, some percentiles, and a tiny in-line histogram(!).</p>
<p>For date variables, it shows the min, max, median, and number of unique dates.</p>
<p>Again, we learn a <em>ton</em> here that we didnâ€™t get from the first few rows of data, or from an initial <code>summary()</code>:</p>
<ul>
<li>There are 6 unique values for <code>bound</code> (I would have expected 4; N, S, E, W).</li>
<li>There are 184 different codes but only 132 descriptions (Do some codes share descriptions? Were some codes mistyped?)</li>
<li>There are 13(!) lines!!</li>
<li>There are 201 stations (I googled â€“ apparently thereâ€™s actually only 75?)</li>
<li><code>min_delay</code> goes from 0 (good) to over 500</li>
</ul>
<p>While Iâ€™m pretty surprised by the results, I think this is a <em>much</em> friendlier way to find some of these things out than by trying to do an analysis and getting weird results and <em>then</em> having to track down how things work (and adjust accordingly).</p>
<p>I also think this kind of visual summary has an added bonus: if you donâ€™t <em>have</em> any expectations or mental models, itâ€™s a fast way to get one.</p>
<p><code>skimr</code> provides a really good jumping-off point for other things to explore to get to know the data. For example, I want to know about the different values for <code>bound</code>, and how those vary by <code>line</code>.</p>
<p><code>skimr</code> works really nicely with grouped data frames, showing a summary <em>for each group</em>. It also has much nicer display for factors than for characters (i.e., showing the top factor levels) and can skim by a selected variable only.</p>
<p>So, we can see summary statistics <em>only</em> for the <code>bound</code> variable, but <em>within</em> each of value of <code>line</code>. Letâ€™s focus on the â€œmainâ€ lines.</p>
<pre class="r"><code>delays %&gt;%
  filter(line %in% c(&quot;BD&quot;, &quot;YU&quot;, &quot;SHP&quot;, &quot;SRT&quot;)) %&gt;%
  mutate(bound = as.factor(bound)) %&gt;%
  group_by(line) %&gt;%
  skim(bound)</code></pre>
<pre><code>## Skim summary statistics
##  n obs: 20254 
##  n variables: 8 
##  group variables: line 
## 
## â”€â”€ Variable type:factor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
##  line variable missing complete    n n_unique
##    BD    bound    1902     7217 9119        5
##   SHP    bound     107      405  512        3
##   SRT    bound     173      544  717        5
##    YU    bound    2055     7851 9906        6
##                         top_counts ordered
##  W: 3657, E: 3543, NA: 1902, N: 10   FALSE
##      W: 219, E: 185, NA: 107, N: 1   FALSE
##      S: 271, N: 261, NA: 173, E: 5   FALSE
##  S: 4064, N: 3763, NA: 2055, E: 14   FALSE</code></pre>
<p>Some irregularities already pop up - for example, BD is an East/West running line, but there are a total of 10 delays on this line in the direction â€œNorthâ€ bound. Similar for YU â€“ it runs North/South, but there are 14 delays running â€œEastâ€ bound. Maybe <code>bound</code> was just coded incorrectly, but Iâ€™d be curious to see what <em>stations</em> these delays are at. For example, if theyâ€™re at Bloor/Yonge station, then maybe the <code>line</code> was coded incorrectly.</p>
<p>These are little inconsistencies that you can totally go down the rabbit-hole on, but are useful to at least <em>know</em> about in case they cause inconsistencies in analysis later on.</p>
<p>So, overall, visual summaries are a really good way to get a feel for your data, verify or build a mental model, and identify areas for further investigation.</p>
</div>
</div>
<div id="opinionated-strategies" class="section level1">
<h1>Opinionated Strategies</h1>
<p>Visual summaries have a pretty important downfall: they rely on you, there, looking at the data. They rely on you knowing what youâ€™re looking for, remembering what youâ€™re looking for (or writing lots of documentation and comments), they rely on interactive coding.</p>
<p>In addition (or instead of) visual summaries, Iâ€™d suggest <em>codifying your assumptions</em>. This is where the â€œopinionatedâ€ bit comes in. Codifying your assumptions requires that your assumptions be explicitly spelled out, and ideally, that your code fails spectacularly and loudly if theyâ€™re <em>not</em> met.</p>
<p>I think that this is better than the alternative case where theyâ€™re not met, but everything still looks â€œokâ€, and bad results can go forward if they donâ€™t raise any red flags.</p>
<div id="assertr-package" class="section level2">
<h2><code>assertr</code> package</h2>
<p>The <a href="https://github.com/ropensci/assertr"><code>assertr</code> package</a>, created by <a href="https://twitter.com/tonyfischetti">Tony Fischetti</a>, is designed to help verify assumptions about data <em>early on</em> in a data pipeline. It forces you to explicitly outline any assumptions about your data, and then alerts you of any deviations from those assumptions.</p>
<p>The <code>assert()</code> function is used to assert assumptions about columns of a data set. By default, it <em>throws an error</em> if the assumptions are not met. If they are met, then the original data frame is returned.</p>
<p>For example, letâ€™s say we want to assert that the column <code>line</code> has to be one of BD, YU, SHP, SRT.</p>
<pre class="r"><code>library(assertr)

delays %&gt;%
  assert(in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;), line)</code></pre>
<pre><code>## Column &#39;line&#39; violates assertion &#39;in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)&#39; 380 times
##     verb redux_fn                        predicate column index value
## 1 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line    27 YU/BD
## 2 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line    71 YU/BD
## 3 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   121 YU/BD
## 4 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   160 YU/BD
## 5 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   180 YU/BD
##   [omitted 375 rows]</code></pre>
<pre><code>## Error: assertr stopped execution</code></pre>
<p>Because this assumption isnâ€™t met, <code>assert</code> returns an error that the assertion was violated 380 times, and shows the first few lines where this is true (with <code>index</code> as the row number), as well as the value that violates that assumption (in the examples it gives, the value â€œYU/BDâ€ is outside of the set we named).</p>
<p><code>assert</code> works using functions called <strong>predicates</strong>. A predicate (apparently a kindergarten-level grammar concept that Iâ€™ve forgotten) says something about the properties or actions of a subject. In this case, the predicate <code>in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)</code> says that the subject, <code>line</code>, takes on one of the values of YU, BD, SHP, and SRT.</p>
<p>There are some other useful predicates built into <code>assert</code>. For example, <code>within_bounds()</code> says that a numeric variable can only take on values in the specified bounds.</p>
<p>If I want to assert the assumption that <code>min_delay</code> has to be a non-negative number, then I would codify this as</p>
<pre class="r"><code>delays %&gt;%
  assert(within_bounds(0, Inf), min_delay)</code></pre>
<pre><code>## # A tibble: 20,735 x 8
##    date       time  station   code  description       min_delay bound line 
##    &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;
##  1 2018-04-01 00:27 ST GEORGâ€¦ MUSAN Unsanitary Vehicâ€¦         8 W     BD   
##  2 2018-04-01 07:56 FINCH STâ€¦ TUSC  Operator Overspeâ€¦         0 S     YU   
##  3 2018-04-01 08:00 YONGE UNâ€¦ MUO   Miscellaneous Otâ€¦         0 &lt;NA&gt;  YU   
##  4 2018-04-01 09:50 KIPLING â€¦ TUSC  Operator Overspeâ€¦         0 W     BD   
##  5 2018-04-01 10:18 VICTORIAâ€¦ MUSC  Miscellaneous Spâ€¦         0 W     BD   
##  6 2018-04-01 10:22 KENNEDY â€¦ EUNT  Equipment - No Tâ€¦         3 W     BD   
##  7 2018-04-01 10:30 WILSON Sâ€¦ PUMEL Escalator/Elevatâ€¦         0 &lt;NA&gt;  YU   
##  8 2018-04-01 11:20 WILSON Sâ€¦ TUSC  Operator Overspeâ€¦         0 S     YU   
##  9 2018-04-01 11:32 FINCH WEâ€¦ MUIRS Injured or ill Câ€¦         0 &lt;NA&gt;  YU   
## 10 2018-04-01 12:00 JANE STAâ€¦ TUSC  Operator Overspeâ€¦         0 W     BD   
## # â€¦ with 20,725 more rows</code></pre>
<p>And this is actually true, so what we get is the original data set! By default, <code>within_bounds()</code> allows <code>NA</code> values, so I should be careful and explicit that my assumption is that <code>min_delay</code> is a positive number <em>with no missing values</em>. To do that, I can use set <code>allow.na = FALSE</code> in <code>within_bounds()</code>.</p>
<p>Or, I can use the <code>not_na()</code> predicate, which specifically checks that each element is not <code>NA</code>!</p>
<pre class="r"><code>delays %&gt;%
  assert(not_na, min_delay)</code></pre>
<pre><code>## Column &#39;min_delay&#39; violates assertion &#39;not_na&#39; 1036 times
##     verb redux_fn predicate    column index value
## 1 assert       NA    not_na min_delay    24    NA
## 2 assert       NA    not_na min_delay    87    NA
## 3 assert       NA    not_na min_delay    99    NA
## 4 assert       NA    not_na min_delay   124    NA
## 5 assert       NA    not_na min_delay   135    NA
##   [omitted 1031 rows]</code></pre>
<pre><code>## Error: assertr stopped execution</code></pre>
<p>And now this fails, because there <em>are</em> <code>NA</code> values.</p>
<p>The other built-in predicate is <code>is_uniq()</code>, which checks whether each element of a variable appears only once (this can be useful for e.g.Â IDs in a data set). You can also include your own predicate, by writing a function that returns TRUE/FALSE.</p>
<p>The <code>assertr</code> functions are designed to be piped together (i.e., all of your assumptions in a single pipe), but require some modification. The default behaviour is for the pipe to break after the first error, e.g.</p>
<pre class="r"><code>delays %&gt;% 
  assert(in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;), line) %&gt;%
  assert(within_bounds(0, Inf), min_delay) %&gt;%
  assert(not_na, min_delay)</code></pre>
<pre><code>## Column &#39;line&#39; violates assertion &#39;in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)&#39; 380 times
##     verb redux_fn                        predicate column index value
## 1 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line    27 YU/BD
## 2 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line    71 YU/BD
## 3 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   121 YU/BD
## 4 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   160 YU/BD
## 5 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   180 YU/BD
##   [omitted 375 rows]</code></pre>
<pre><code>## Error: assertr stopped execution</code></pre>
<p>only tells us that <code>line</code> violated the <code>in_set()</code> assumption, and nothing about <code>min_delay</code> â€“ even though we know the <code>not_na</code> assumption isnâ€™t met.</p>
<p>To remedy this, I use <code>chain_start()</code> at the beginning of the chain of assumptions, and <code>chain_end()</code> at the end. This overwrites the default behaviour of <code>assert</code> (to stop after the first failure) and instead shows information about all errors. Iâ€™m using the <code>error_stop</code> argument here too, otherwise it literally prints <em>all of the errors</em> and that makes this post very, very long.</p>
<pre class="r"><code>delays %&gt;% 
  chain_start() %&gt;%
  assert(in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;), line) %&gt;%
  assert(within_bounds(0, Inf), min_delay) %&gt;%
  assert(not_na, min_delay) %&gt;%
  chain_end(error_fun = error_stop)</code></pre>
<pre><code>## Column &#39;line&#39; violates assertion &#39;in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)&#39; 380 times
##     verb redux_fn                        predicate column index value
## 1 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line    27 YU/BD
## 2 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line    71 YU/BD
## 3 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   121 YU/BD
## 4 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   160 YU/BD
## 5 assert       NA in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;)   line   180 YU/BD
##   [omitted 375 rows]
## 
## 
## Column &#39;min_delay&#39; violates assertion &#39;not_na&#39; 1036 times
##     verb redux_fn predicate    column index value
## 1 assert       NA    not_na min_delay    24    NA
## 2 assert       NA    not_na min_delay    87    NA
## 3 assert       NA    not_na min_delay    99    NA
## 4 assert       NA    not_na min_delay   124    NA
## 5 assert       NA    not_na min_delay   135    NA
##   [omitted 1031 rows]</code></pre>
<pre><code>## Error: assertr stopped execution</code></pre>
<p>There are definitely more functions in <code>assertr</code> â€“ <code>assert</code> only allows you to make assumptions about columns. It may be useful to make assertions about the overall data structure (using <code>verify()</code>), about values of a variable in relation to its mean (using <code>insist()</code>), or e.g.Â about attributes of a row overall (using <code>assert_rows()</code>).</p>
<p>In the end, though, a huge plus of <code>assertr</code> functions is that when all of the assumptions are satisfied, <em>the result is just the original data set</em>. This allows you to check assumptions <em>and</em> do calculations all in one go.</p>
<p>Letâ€™s say we have a cleaned version of <code>delays</code>, where all <code>NA</code> values of <code>min_delay</code> have been dealt with and any â€œnon-stationsâ€ are removed.</p>
<p>Because all of the assumptions are met, the result from the chain of assumptions is just <em>the original data set</em>, and we can aggregate and plot as we wish!</p>
<pre class="r"><code>delays_clean %&gt;% 
  chain_start() %&gt;%
  assert(in_set(&quot;YU&quot;, &quot;BD&quot;, &quot;SHP&quot;, &quot;SRT&quot;), line) %&gt;%
  assert(within_bounds(0, Inf), min_delay) %&gt;%
  assert(not_na, min_delay) %&gt;%
  chain_end() %&gt;%
  group_by(line, description) %&gt;%
  summarise(delays = sum(min_delay)) %&gt;%
  arrange(-delays) %&gt;%
  slice(1:5) %&gt;%
  ggplot(aes(x = description,
             y = delays)) +
  geom_col() + 
  facet_wrap(vars(line), 
             scales = &quot;fixed&quot;,
             nrow = 1) +
  coord_flip()</code></pre>
<p><img src="/posts/2019/2019-03-05-new-data-strategies_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>So now, for real, we see the top 5 causes for delays on the TTC subway and SRT in 2018 â€“ â€œForce Majeureâ€ is less common, and we see some rough, but true causes of TTC delays â€“ disorderly patron, ill customers, the ATC project, etc.</p>
<p>Interestingly enough, â€œUnauthorized at Track Levelâ€ still doesnâ€™t crack the top 5 ğŸ¤”</p>
</div>
</div>
<div id="the-end" class="section level1">
<h1>The end!</h1>
<p>I hope Iâ€™ve managed to instill some good approaches around working with a new data set, specifically:</p>
<ul>
<li>Be weary of diving right into results</li>
<li>Efficiently visualize your data to verify or build mental models</li>
<li>Be liberal with rabbit holes, investigations, and edge cases</li>
<li>Codify your assumptions so that it is them, not you, who fail spectacularly</li>
</ul>
<p>Bye bye!</p>
</div>
